---
id: tutorial-metrics-evaluation-criteria
title: Deciding on your Evaluation Criteria
sidebar_label: Deciding your Evaluation Criteria
---

The metrics you choose to evaluate your LLM **depend on the evaluation criteria** you define. These criteria will be used to assess the specific aspects of your LLM that you wish to improve, ensuring they align with your goals and user needs.

Defining a clear evaluation criteria is essential, as it transforms your subjective values (what matters to you and your users, and what you wish to improve) into actionable steps (selecting the right metrics).

:::tip
When defining your evaluation criteria, you'll need to consider **what matters most to you**, **what your users care about**, and **where your model's performance could be enhanced**. If this isn't entirely clear at first, it might be helpful to inspect a few input-response pairs with your LLM application.
:::

## Example Interactions:

Let's begin by examining these **5 input-response pairs** between some hypothetical users and the medical diagnosis chatbot that we set up in [the previous section](tutorial-llm-application-example). We'll assess whether each interaction meets our expectations or highlights potential issues, which will help us refine our evaluation criteria.

### Input-Response Pair 1 ✅

The following interaction is an **ideal example** of how our medical chatbot should respond, because it asks clarifying questions before attempting to make a diagnosis. As a medical company, making accurate diagnoses is extremely important, so it's necessary to be asking these kinds of question before jumping to conclusions.

```python
user_query = """
  Hey, I've been experiencing headaches lately.
"""
llm_output = """
  I can help you with that. Could you please provide more specific details about 
  your headaches? For example, the location, intensity, duration, frequency, and 
  any other symptoms you might be experiencing alongside the headaches.
"""
```

### Input-Response Pair 2 ❌

On the other hand, the following **interaction** is problematic. While the user is primarily seeking a diagnosis, the chatbot unnecessarily asks for the patient’s name and appointment details, before any sort of appointment is requested by the user.

```python
user_query = """
  I'm been coughing a lot lately.
"""
llm_output = """
  Could you please provide your name, the date for the appointment, and your 
  email address?     
"""
```

### Input-Response Pair 3 ❌

For similar but opposite reasons, the following interaction is undesirable, namely because while the user is clearly trying to book an appointment, the chatbot responds tangentially by asking about the user’s symptoms, rather than addressing the appointment request.

```python
user_query = """
  I'm feeling pretty sick, can I book an appointment tomorrow?
"""
llm_output = """
  I can help you with that. Could you please provide more specific details 
  about your symptoms? This will help us in making a more accurate diagnosis.
"""
```
While some may argue that the order of gathering appointment details and making a diagnosis isn’t critical—since both tasks will likely be completed—it’s essential for our medical chatbot to provide responses that are relevant and directly address the user’s query. This approach ensures the chatbot appears intelligent and authentic, building trust and encouraging patients to rely on it for their diagnostic needs.  

### Input-Response Pair 4 ✅

The following interaction is acceptable because the chatbot accurately records the user’s information, stores it in the appropriate fields, and presents it back to the user for confirmation.

```python
user_query = """
  My name is John Doe. My email is johndoe@gmail.com, and I would like to make an
  appointment on November 23, 2022.
"""
llm_output = """
  Please confirm the following details: Name: John Doe, Email: johndoe@gmail.com, 
  Date: November 23, 2022, Symptoms: Frequent coughing, Diagnosis: Frequent coughing 
  may indicate chronic bronchitis, especially if accompanied by phlegm, wheezing, or 
  shortness of breath.. Type 'confirm' to finalize or 'edit' to modify.
"""
```

### Input-Response Pair 5 ❌

The following input-response pair is unacceptable because it overdiagnoses the patient, potentially resulting in a false positive. A runny nose alone does not provide enough information for a diagnosis, making it essential for the chatbot to ask clarifying questions before offering any conclusions.

```python
user_query = """
  I have a runny nose. What could be causing it?
"""
llm_output = """
  A runny nose can be a symptom of conditions such as allergic rhinitis, where 
  histamine interacts with receptors on blood vessels, leading to fluid buildup, 
  swelling, and redness. If you'd like to schedule an appointment for a detailed 
  diagnosis or treatment, feel free to let me know!
"""
```

Through inspecting just five example interactions with the medical chatbot—two acceptable and three problematic—we've already discovered the following values we care about, and that we think users care about:  

- **Empathy and direct engagement:** Users expect the chatbot to address them directly, guiding the flow of the conversation in a way that feels natural and responsive.  
- **Safety and accuracy in diagnoses:** Users depend on accurate responses that neither overdiagnose nor underdiagnose based on the symptoms provided.  
- **Trustworthiness:** Every interaction should reinforce the chatbot’s reliability, fostering confidence in its capability as a medical assistant.  

## Defining Our Evaluation Criteria

Based on these insights, we identified three specific areas where our LLM needs improvement:  

1. **Directly addressing the user:** The chatbot should engage users personally and conversationally to build trust and maintain control of the interaction.  
2. **Avoiding overdiagnosis:** It should avoid premature or unsupported conclusions, particularly without sufficient details.  
3. **Providing accurate diagnoses:** Diagnoses must be reliable and based on the provided symptoms, minimizing risks and errors.  

:::info important  
These areas of improvement represent yoru **evaluation criteria**—standards for assessing each input-response pair.  
:::  

### Why These Criteria Matter  

Each criterion reflects user expectations and critical performance aspects:  

- **Directly addressing the user** ensures two essential outcomes: users feel in control of the interaction, and the chatbot is perceived as an intelligent, trustworthy assistant.  
- **Avoiding overdiagnosis and ensuring accuracy** safeguard against false positives (overdiagnosis) and false negatives (underdiagnosis), both of which could erode trust and lead to severe consequences.  

By focusing on these criteria, we ensure our evaluation process aligns with both our values and user needs. With this foundation in place, we can now proceed to the next step: selecting metrics that effectively measure these key areas of performance.  





